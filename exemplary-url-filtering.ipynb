{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello everyone! Below I'm trying to show you the whole process I've went through to filter collected URLs by hand and try to extract only ones that promised some text data from the forum discussions as this is the main purpose of this task. \n",
    "\n",
    "Of course, it's possible to create separate URL sets from shop or others that are included here. However it's not the main point of concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the URLs from a .txt file\n",
    "with open('kfd.txt', 'r', encoding='utf-8') as f:\n",
    "    txt = f.read().split()\n",
    "\n",
    "# Load URLs to Pandas DataFrame\n",
    "df = pd.DataFrame(columns=['urls'],\n",
    "                  data=txt)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: just to let you know, original input used for this analysis contained approx. 7.3M different URLs. That's a starting point - let's see where we're going to end up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the main part of work that has to be done happens.\n",
    "\n",
    "**CAUTION: Please be aware that the prefixes/suffixes will differ depending on the website you're currently processing.**\n",
    "\n",
    "My workflow was:\n",
    "- scroll through the txt file to find an interesting URL (i.ex. containing 'sklep-kdf' in it)\n",
    "- add another exclusion to the set below\n",
    "- run the cell below to find how many URLs are affected\n",
    "- rince and repeat until satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7271459\n"
     ]
    }
   ],
   "source": [
    "# We're interested only in forum texts, therefore 'akademia.kfd' website should be dropped\n",
    "df['akademia-kfd'] = df['urls'].apply(lambda x: 'akademia.kfd' in x)\n",
    "\n",
    "# If something is not a 'kfd' website we also dump it\n",
    "df['non-kfd'] = df['urls'].apply(lambda x: 'kfd' not in x)\n",
    "\n",
    "# 'getlastpost' directs us to a particular post of an user, not a whole topic\n",
    "df['getlastpost'] = df['urls'].apply(lambda x: 'getlastpost' in x)\n",
    "\n",
    "# Some URLs were concatenated in wrong way (i.ex. double 'https://' part in the URL)\n",
    "df['multiple-http'] = df['urls'].apply(lambda x: 'http://h' in x)\n",
    "\n",
    "# Another part of URL leading to nowhere interesting\n",
    "df['/s/'] = df['urls'].apply(lambda x: '/s/' in x)\n",
    "\n",
    "# 'sklep-kfd' leads to shopping part, we're not interested in it\n",
    "df['sklep-kfd'] = df['urls'].apply(lambda x: 'sklep.kfd' in x)\n",
    "\n",
    "# Some JS/PHP component, not useful\n",
    "df['component'] = df['urls'].apply(lambda x: 'component' in x)\n",
    "\n",
    "# Search results, same outcome as 'getlastpost' above\n",
    "df['find-post'] = df['urls'].apply(lambda x: 'view=findpost' in x)\n",
    "\n",
    "# Again, concatenating mistake from crawler\n",
    "df['...'] = df['urls'].apply(lambda x: '...' in x)\n",
    "\n",
    "# These two always lead to the same version of website, params changed nothing\n",
    "df['langid'] = df['urls'].apply(lambda x: 'langid=' in x)\n",
    "df['setlanguage'] = df['urls'].apply(lambda x: 'setlanguage=' in x)\n",
    "\n",
    "# Returns topic search results, not the content of topics\n",
    "df['sort_by'] = df['urls'].apply(lambda x: 'sort_by=' in x)\n",
    "\n",
    "# Attachments are not texts, so ditch them too\n",
    "df['attach_id'] = df['urls'].apply(lambda x: 'attach_id=' in x)\n",
    "\n",
    "# Again, similar to 'sort_by'\n",
    "df['search_app_filters'] = df['urls'].apply(lambda x: 'search_app_filters' in x)\n",
    "\n",
    "# Leads to external portal, which does not exist anymore\n",
    "df['nasza_klasa'] = df['urls'].apply(lambda x: 'nasza_klasa' in x)\n",
    "\n",
    "# Yet another concatenation mistake\n",
    "df['//'] = df['urls'].apply(lambda x: x.startswith('//'))\n",
    "\n",
    "# Again - something useless\n",
    "df['page__pid'] = df['urls'].apply(lambda x: 'page__pid' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "akademia-kfd  getlastpost  non-kfd  multiple-http  /s/    sklep-kfd  component  find-post  ...    langid  sort_by  attach_id  search_app_filters  nasza_klasa  setlanguage  //     page__pid\n",
       "False         False        False    False          False  False      False      False      False  True    False    False      False               False        True         False  False        2145787\n",
       "                                                                                                  False   False    False      True                False        False        False  False        1973045\n",
       "                                                                                                                              False               True         False        False  False        1238751\n",
       "                                                                                                                                                  False        False        False  False         779911\n",
       "                                                          True       False      False      False  False   False    False      False               False        False        False  False         346291\n",
       "              True         False    False          False  False      False      False      False  False   False    False      False               False        False        False  False         317098\n",
       "              False        False    False          False  False      False      False      False  True    True     False      False               False        True         False  False         164096\n",
       "                                                                                                  False   False    True       False               False        False        False  False         129716\n",
       "                                                                                                          True     False      False               False        False        False  False          85602\n",
       "                                                                                                  True    False    True       False               False        True         False  False          80716\n",
       "                           True     False          False  False      False      False      False  False   False    False      False               False        False        False  False           4480\n",
       "                           False    False          False  False      False      False      False  True    False    False      True                False        True         False  False           1472\n",
       "                                                                                True       False  False   False    False      False               False        False        False  False           1172\n",
       "                                    True           False  False      False      False      False  False   False    False      False               False        False        False  False            805\n",
       "                                    False          True   False      False      False      False  False   False    False      False               False        False        False  False            772\n",
       "                                                   False  False      False      False      True   False   False    False      True                False        False        False  False            576\n",
       "                                                          True       False      False      True   False   False    False      False               False        False        False  False            330\n",
       "                                                          False      False      False      True   False   False    False      False               False        False        False  False            213\n",
       "                                                                                           False  False   False    False      False               False        False        False  True             194\n",
       "True          False        False    False          False  False      False      False      False  False   False    False      False               False        False        False  False            103\n",
       "False         False        False    False          False  False      False      True       False  True    False    False      False               False        True         False  False             94\n",
       "                                                                                False      True   True    False    False      False               False        True         False  False             80\n",
       "                                                                     True       False      False  False   False    False      True                False        False        False  False             54\n",
       "              True         False    False          False  False      False      False      False  True    False    False      False               False        True         False  False             36\n",
       "              False        False    True           False  False      False      False      False  False   False    False      False               False        False        False  True              13\n",
       "                                    False          False  False      True       False      False  True    False    False      False               False        True         False  False             12\n",
       "                                    True           False  False      False      False      False  False   False    True       False               False        False        False  False             11\n",
       "                                                                                           True   False   False    False      False               False        False        False  False              8\n",
       "                                    False          False  False      True       False      False  False   False    False      False               False        False        False  False              7\n",
       "              True         True     False          False  False      False      False      False  False   False    False      False               False        False        False  False              6\n",
       "              False        False    True           False  True       False      False      False  False   False    False      False               False        False        False  False              5\n",
       "                                    False          False  True       True       False      False  False   False    False      False               False        False        False  False              2\n",
       "              True         False    False          False  False      True       False      False  False   False    False      False               False        False        False  False              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I've created a simple matrix to check how many entries are\n",
    "# per particular argument \n",
    "df[['akademia-kfd', 'getlastpost', 'non-kfd', 'multiple-http',\n",
    "    '/s/', 'sklep-kfd', 'component', 'find-post', '...',\n",
    "    'langid', 'sort_by', 'attach_id', 'search_app_filters',\n",
    "    'nasza_klasa', 'setlanguage', '//', 'page__pid']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779911"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New DataFrame where we do include only the URLs we'd like to inspect closely\n",
    "df_v1 = df[(df['akademia-kfd']==False) & (df['getlastpost']==False) &\n",
    "   (df['non-kfd']==False) & (df['multiple-http']==False) &\n",
    "   (df['/s/']==False) & (df['sklep-kfd']==False) &\n",
    "   (df['component']==False) & (df['find-post']==False) &\n",
    "   (df['...']==False) & (df['langid']==False) &\n",
    "   (df['sort_by']==False) & (df['attach_id']==False) &\n",
    "   (df['search_app_filters']==False) & (df['nasza_klasa']==False) &\n",
    "   (df['setlanguage']==False) & (df['//']==False) &\n",
    "   (df['page__pid']==False)]\n",
    "\n",
    "len(df_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, from 7.3M input URLs, I've ended up with about 0.78M which is about 10% of total crawled URLs. The whole analysis I've perfomed above took me about 45 minutes but due to this - I've saved at least full day of processing empty/useless links that only would either take time (attachments, sort results, other websites like `nasza-klasa`) or would duplicate entries in the dataset (`lang_id`, `setlanguage` or `getlastpost`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files written succesfully!\n",
      "File closed\n"
     ]
    }
   ],
   "source": [
    "# Saving the remaining URLs to new file ready to serve as input to another tool\n",
    "with open('kfd-cleared.txt', 'w', encoding='utf-8') as f:\n",
    "\tfor url in df_v1['urls']:\n",
    "\t\tf.write(url + '\\n')\n",
    "\tprint('Files written succesfully!')\n",
    "\n",
    "f.close()\n",
    "print('File closed')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** After the final processing with `article_crawler.py`, the tool managed to collect 0.33M documents. It's about 40% of cleared and processed URLs (and 4% of whole input set of URLs). This is mostly due to some faulty URLs containing no data got under our radar and due to the settings of the tool used (i.ex. minimal text length)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
